{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import datag\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import VGG16\n",
    "# from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abraham_Danilo_Miranda_Lopez', 'Alejandro_Benjamin_Rocano_Lopez', 'Alex_Ignacio_Tigselema_Pacheco', 'andres', 'Andres_Patricio_Tapia_Gonzalez', 'Bryan_Eduardo_Martinez_Nunez', 'Christian_Marcelo_Jaramillo_Collazo', 'Diana_Jazmin_Pinchao_Fante', 'Diego_Fernando_Cata_Saltos', 'Edison_Orlando_Lopez_Galarza', 'Jeniffer_Paulina_Yaguana_Caraguay', 'Jonathan_Jose_Pazmino_Fiallos', 'Luis_Fernando_Zerna_Ramos', 'Marco_Farid_Ruano_Caicedo', 'mateo', 'Pablo_Jhoel_Puetate_Mier', 'Silvia_Esthefania_Villacres_Chico', 'Thais_Eliana_Armijos_Troya']\n",
      "total etiquetas: 18000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total datos: 18000\n"
     ]
    }
   ],
   "source": [
    "path_dataset = 'D:/GitHub/reconocieminto-facial-con-python/dataset/'\n",
    "nombres_directorios = datag.extraer_nombres(path_dataset)\n",
    "print(nombres_directorios)\n",
    "\n",
    "etiquetas = []\n",
    "for index, directorio in enumerate(nombres_directorios):\n",
    "    nombres_archivos = datag.extraer_nombres(path_dataset + directorio)\n",
    "    total_archivos = len(nombres_archivos)\n",
    "    for _ in range(total_archivos):\n",
    "        etiquetas.append(index)\n",
    "print(f'total etiquetas: {len(etiquetas)}')\n",
    "\n",
    "imagenes = [] \n",
    "for directorio in nombres_directorios:\n",
    "    nombres_archivos = datag.extraer_nombres(path_dataset + directorio)\n",
    "    for nombre_archivo in nombres_archivos:\n",
    "        img_array = cv2.imread(path_dataset + directorio + '/' + nombre_archivo, cv2.IMREAD_GRAYSCALE)\n",
    "        img_array = img_array / 255 # normalizo\n",
    "        imagenes.append(img_array)\n",
    "print(f'total datos: {len(imagenes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(imagenes, etiquetas, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "xtrain = np.array(xtrain)\n",
    "ytrain = np.array(ytrain)\n",
    "\n",
    "xtest = np.array(xtest)\n",
    "ytest = np.array(ytest)\n",
    "\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# # Construir el modelo VGG16 completo agregando capas adicionales\n",
    "# x = base_model.output\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# x = layers.Dense(4096, activation='relu')(x)\n",
    "# x = layers.Dense(4096, activation='relu')(x)\n",
    "# output = layers.Dense(len(nombres_directorios), activation='softmax')(x)  # Reemplaza 'num_classes' con el número de clases de tu problema\n",
    "\n",
    "# # Crear el modelo final\n",
    "# modelo = Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 98, 98, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 49, 49, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 23, 23, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 10, 10, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               3277056   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 18)                9234      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3510546 (13.39 MB)\n",
      "Trainable params: 3510546 (13.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(xtrain[0].shape[0],xtrain[0].shape[0],1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(512, activation=tf.nn.relu),\n",
    "    layers.Dense(len(nombres_directorios), activation=tf.nn.softmax)\n",
    "])\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "422/422 [==============================] - 176s 408ms/step - loss: 1.0770 - accuracy: 0.6389\n",
      "Epoch 2/12\n",
      "422/422 [==============================] - 170s 403ms/step - loss: 0.2685 - accuracy: 0.9144\n",
      "Epoch 3/12\n",
      "422/422 [==============================] - 166s 392ms/step - loss: 0.1550 - accuracy: 0.9493\n",
      "Epoch 4/12\n",
      "422/422 [==============================] - 164s 389ms/step - loss: 0.0944 - accuracy: 0.9691\n",
      "Epoch 5/12\n",
      "422/422 [==============================] - 161s 382ms/step - loss: 0.0805 - accuracy: 0.9739\n",
      "Epoch 6/12\n",
      "422/422 [==============================] - 167s 397ms/step - loss: 0.0640 - accuracy: 0.9790\n",
      "Epoch 7/12\n",
      "422/422 [==============================] - 161s 382ms/step - loss: 0.0542 - accuracy: 0.9816\n",
      "Epoch 8/12\n",
      "422/422 [==============================] - 116s 275ms/step - loss: 0.0459 - accuracy: 0.9845\n",
      "Epoch 9/12\n",
      "422/422 [==============================] - 117s 278ms/step - loss: 0.0537 - accuracy: 0.9839\n",
      "Epoch 10/12\n",
      "422/422 [==============================] - 120s 285ms/step - loss: 0.0400 - accuracy: 0.9871\n",
      "Epoch 11/12\n",
      "422/422 [==============================] - 119s 282ms/step - loss: 0.0417 - accuracy: 0.9870\n",
      "Epoch 12/12\n",
      "422/422 [==============================] - 119s 282ms/step - loss: 0.0339 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x185fb6fefd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(xtrain, ytrain, epochs=12, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 9s 63ms/step\n",
      "Exactitud: 0.9777777777777777\n",
      "Precisión: 0.9777285075888541\n",
      "Sensibilidad: 0.9775741881311958\n",
      "Puntuación F1: 0.9774287186505615\n"
     ]
    }
   ],
   "source": [
    "predicciones = modelo.predict(xtest)\n",
    "y_pred = np.argmax(predicciones, axis=1)\n",
    "\n",
    "exactitud = accuracy_score(ytest, y_pred)\n",
    "precision = precision_score(ytest, y_pred, average='macro')\n",
    "sensibilidad = recall_score(ytest, y_pred, average='macro')\n",
    "puntuacion_f1 = f1_score(ytest, y_pred, average='macro')\n",
    "\n",
    "print(\"Exactitud:\", exactitud)\n",
    "print(\"Precisión:\", precision)\n",
    "print(\"Sensibilidad:\", sensibilidad)\n",
    "print(\"Puntuación F1:\", puntuacion_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descgargar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "modelo.save('modelo_cnn')\n",
    "modelo.save_weights('pesos_cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rostros",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
